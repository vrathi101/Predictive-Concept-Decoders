W0104 14:54:43.436000 12762 torch/distributed/run.py:803] 
W0104 14:54:43.436000 12762 torch/distributed/run.py:803] *****************************************
W0104 14:54:43.436000 12762 torch/distributed/run.py:803] Setting OMP_NUM_THREADS environment variable for each process to be 1 in default, to avoid your system being overloaded, please further tune the variable for optimal performance in your application as needed. 
W0104 14:54:43.436000 12762 torch/distributed/run.py:803] *****************************************
Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
epoch 1/100: 0it [00:00, ?it/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...
To disable this warning, you can either:
	- Avoid using `tokenizers` before the fork if possible
	- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)
epoch 1/100: 0it [00:00, ?it/s]epoch 1/100: 0it [00:30, ?it/s]
[rank0]: Traceback (most recent call last):
[rank0]:   File "/workspace/predictive_concept_decoders/predictive_concept_decoders.py", line 584, in <module>
[rank0]:     do_train_full()
[rank0]:   File "/workspace/predictive_concept_decoders/predictive_concept_decoders.py", line 492, in do_train_full
[rank0]:     for step, train_batch in pbar:
[rank0]:   File "/usr/local/lib/python3.11/dist-packages/tqdm/std.py", line 1181, in __iter__
[rank0]:     for obj in iterable:
[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py", line 732, in __next__
[rank0]:     data = self._next_data()
[rank0]:            ^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py", line 1506, in _next_data
[rank0]:     return self._process_data(data, worker_id)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py", line 1541, in _process_data
[rank0]:     data.reraise()
[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/_utils.py", line 769, in reraise
[rank0]:     raise exception
[rank0]: huggingface_hub.errors.HfHubHTTPError: Caught HfHubHTTPError in DataLoader worker process 0.
[rank0]: Original Traceback (most recent call last):
[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/worker.py", line 349, in _worker_loop
[rank0]:     data = fetcher.fetch(index)  # type: ignore[possibly-undefined]
[rank0]:            ^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.11/dist-packages/torch/utils/data/_utils/fetch.py", line 33, in fetch
[rank0]:     data.append(next(self.dataset_iter))
[rank0]:                 ^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/workspace/predictive_concept_decoders/predictive_concept_decoders.py", line 213, in __iter__
[rank0]:     ds = load_dataset(
[rank0]:          ^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.11/dist-packages/datasets/load.py", line 1492, in load_dataset
[rank0]:     builder_instance = load_dataset_builder(
[rank0]:                        ^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.11/dist-packages/datasets/load.py", line 1137, in load_dataset_builder
[rank0]:     dataset_module = dataset_module_factory(
[rank0]:                      ^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.11/dist-packages/datasets/load.py", line 1036, in dataset_module_factory
[rank0]:     raise e1 from None
[rank0]:   File "/usr/local/lib/python3.11/dist-packages/datasets/load.py", line 1009, in dataset_module_factory
[rank0]:     ).get_module()
[rank0]:       ^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.11/dist-packages/datasets/load.py", line 633, in get_module
[rank0]:     data_files = DataFilesDict.from_patterns(
[rank0]:                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.11/dist-packages/datasets/data_files.py", line 708, in from_patterns
[rank0]:     else DataFilesList.from_patterns(
[rank0]:          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.11/dist-packages/datasets/data_files.py", line 601, in from_patterns
[rank0]:     resolve_pattern(
[rank0]:   File "/usr/local/lib/python3.11/dist-packages/datasets/data_files.py", line 367, in resolve_pattern
[rank0]:     for filepath, info in fs.glob(pattern, detail=True, **glob_kwargs).items()
[rank0]:                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.11/dist-packages/huggingface_hub/hf_file_system.py", line 528, in glob
[rank0]:     return super().glob(path, **kwargs)
[rank0]:            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.11/dist-packages/fsspec/spec.py", line 604, in glob
[rank0]:     allpaths = self.find(root, maxdepth=depth, withdirs=True, detail=True, **kwargs)
[rank0]:                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.11/dist-packages/huggingface_hub/hf_file_system.py", line 567, in find
[rank0]:     out = self._ls_tree(
[rank0]:           ^^^^^^^^^^^^^^
[rank0]:   File "/usr/local/lib/python3.11/dist-packages/huggingface_hub/hf_file_system.py", line 471, in _ls_tree
[rank0]:     for path_info in tree:
[rank0]:   File "/usr/local/lib/python3.11/dist-packages/huggingface_hub/hf_api.py", line 3191, in list_repo_tree
[rank0]:     for path_info in paginate(path=tree_url, headers=headers, params={"recursive": recursive, "expand": expand}):
[rank0]:   File "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_pagination.py", line 37, in paginate
[rank0]:     hf_raise_for_status(r)
[rank0]:   File "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_http.py", line 475, in hf_raise_for_status
[rank0]:     raise _format(HfHubHTTPError, str(e), response) from e
[rank0]: huggingface_hub.errors.HfHubHTTPError: 502 Server Error: Bad Gateway for url: https://huggingface.co/api/datasets/HuggingFaceFW/fineweb/tree/9bb295ddab0e05d785b879661af7260fed5140fc/data?recursive=True&expand=False

[rank0]:[W104 14:55:23.377239813 ProcessGroupNCCL.cpp:1524] Warning: WARNING: destroy_process_group() was not called before program exit, which can leak resources. For more info, please see https://pytorch.org/docs/stable/distributed.html#shutdown (function operator())
Too many dataloader workers: 4 (max is dataset.num_shards=2). Stopping 2 dataloader workers.
